# Story Generation System - Architecture Documentation

**Version:** 1.3.1  
**Last Updated:** 2024-11-07  
**Author:** AI Story Generation Team

---

## Table of Contents

1. [System Overview](#system-overview)
2. [Architecture Diagram](#architecture-diagram)
3. [Data Flow](#data-flow)
4. [Core Components](#core-components)
5. [Module Details](#module-details)
6. [File Structure](#file-structure)
7. [Input/Output Specifications](#inputoutput-specifications)
8. [API Integration](#api-integration)
9. [Checkpoint & Recovery](#checkpoint--recovery)
10. [Cost Tracking](#cost-tracking)

---

## System Overview

Há»‡ thá»‘ng tá»± Ä‘á»™ng sinh truyá»‡n tu tiÃªn/kiáº¿m hiá»‡p báº±ng AI, sá»­ dá»¥ng Google Gemini API. Há»‡ thá»‘ng hoáº¡t Ä‘á»™ng theo mÃ´ hÃ¬nh pipeline vá»›i kháº£ nÄƒng checkpoint vÃ  resume.

### Key Features

- âœ… **Project-based structure**: Má»—i project cÃ³ folder riÃªng biá»‡t
- âœ… **Multi-batch generation**: Sinh truyá»‡n theo batch (má»—i batch = 5 chapters)
- âœ… **Entity tracking**: Theo dÃµi nhÃ¢n váº­t, Ä‘á»‹a Ä‘iá»ƒm, báº£o váº­t, cÃ´ng phÃ¡p
- âœ… **Event & conflict management**: Quáº£n lÃ½ sá»± kiá»‡n vÃ  mÃ¢u thuáº«n
- âœ… **Checkpoint system**: CÃ³ thá»ƒ dá»«ng vÃ  tiáº¿p tá»¥c báº¥t ká»³ lÃºc nÃ o
- âœ… **Cost tracking**: Theo dÃµi chi phÃ­ API calls
- âœ… **Detailed logging**: Log táº¥t cáº£ LLM requests/responses

### Technology Stack

- **Language**: Python 3.8+
- **LLM Provider**: Google Gemini (gemini-2.5-flash, gemini-2.5-pro)
- **Config**: YAML
- **Data Format**: JSON
- **Storage**: File-based (JSON, TXT)

---

## Architecture Diagram

### High-Level System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Story Generator                           â”‚
â”‚                         (Orchestrator)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚            â”‚            â”‚              â”‚              â”‚
    â–¼            â–¼            â–¼              â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Motif  â”‚  â”‚Outline â”‚  â”‚  Entity  â”‚  â”‚ Chapter  â”‚  â”‚   Post   â”‚
â”‚ Loader â”‚  â”‚  Gen   â”‚  â”‚ Manager  â”‚  â”‚  Writer  â”‚  â”‚Processor â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚           â”‚            â”‚              â”‚              â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚            â”‚            â”‚
                 â–¼            â–¼            â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   LLM   â”‚  â”‚Checkpointâ”‚  â”‚  Cost   â”‚
            â”‚ Client  â”‚  â”‚ Manager  â”‚  â”‚ Tracker â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Gemini API     â”‚
        â”‚  (Pool of Keys) â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Interaction Flow

```
User Input (CLI)
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Main Orchestrator                         â”‚
â”‚  - Initialize components                                      â”‚
â”‚  - Manage batch generation loop                               â”‚
â”‚  - Coordinate module interactions                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚                     â”‚                  â”‚               â”‚
   â–¼                     â–¼                  â–¼               â–¼
Step 1:              Step 2:           Step 3-4:        Step 5:
Load Motif        Gen Outline      Extract Entities   Write Chapter
   â”‚                     â”‚                  â”‚               â”‚
   â”‚                     â”‚                  â”‚               â”‚
   â”‚                     â”‚                  â”‚               â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                         Step 6-8:
                      Post-Processing
                    (Events/Conflicts/Summary)
                              â”‚
                              â–¼
                         Save & Track
                    (Files, Checkpoint, Cost)
```

---

## Data Flow

### Complete Pipeline Data Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ data/       â”‚
â”‚ motif.json  â”‚ â”€â”€â”
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
                  â”‚
                  â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ 1. Motif Loaderâ”‚
         â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
         â”‚ Input:  motif  â”‚
         â”‚ Output: motif  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ 2. Outline Generator â”‚
      â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
      â”‚ Input:  motif/contextâ”‚
      â”‚ Output: 5 outlines   â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ 3. Entity Manager    â”‚
      â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
      â”‚ Input:  outlines     â”‚
      â”‚ Output: entities{}   â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ 4. Chapter Writer    â”‚  â—„â”€â”€â”€ Context (entities, events, summaries)
      â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
      â”‚ Input:  outline +    â”‚
      â”‚         context      â”‚
      â”‚ Output: chapter text â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ 5. Post Processor    â”‚
      â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
      â”‚ Input:  chapter text â”‚
      â”‚ Output: events[]     â”‚
      â”‚         conflicts[]  â”‚
      â”‚         summary      â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ projects/     â”‚
         â”‚ {project_id}/ â”‚
         â”‚   outputs/    â”‚
         â”‚   logs/       â”‚
         â”‚   checkpoints/â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Detailed Data Flow per Chapter

```
Chapter N Generation Flow:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Input Stage:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”Œâ”€ Chapter Outline (from Step 2)
â”‚  â€¢ chapter_number
â”‚  â€¢ title
â”‚  â€¢ summary
â”‚  â€¢ key_events[]
â”‚  â€¢ characters[]
â”‚  â€¢ settings[]
â”‚  â€¢ conflicts[]
â”‚  â€¢ foreshadowing[]
â”‚
â”œâ”€ Context (from previous chapters)
â”‚  â”œâ”€ Entities
â”‚  â”‚  â”œâ”€ characters[]
â”‚  â”‚  â”œâ”€ locations[]
â”‚  â”‚  â”œâ”€ items[]
â”‚  â”‚  â”œâ”€ techniques[]
â”‚  â”‚  â””â”€ factions[]
â”‚  â”‚
â”‚  â”œâ”€ Events (recent important events)
â”‚  â”‚  â””â”€ [{description, importance, consequences}]
â”‚  â”‚
â”‚  â”œâ”€ Conflicts (unresolved)
â”‚  â”‚  â””â”€ [{type, timeline, status}]
â”‚  â”‚
â”‚  â”œâ”€ Summaries
â”‚  â”‚  â”œâ”€ super_summary (overall story)
â”‚  â”‚  â””â”€ recent_summaries (last 2 chapters)
â”‚  â”‚
â”‚  â””â”€ Previous Chapter End (last 1000 chars)
â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Processing Stage:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”Œâ”€ LLM Call (Gemini API)
â”‚  Input:  Combined prompt from above
â”‚  Model:  gemini-2.5-pro (chapter writing)
â”‚  Temp:   0.85
â”‚  Output: Chapter text (5000+ words)
â”‚
â”œâ”€ Save to File
â”‚  Path: projects/{id}/outputs/chapters/chapter_{N}.txt
â”‚
â””â”€ Checkpoint
   Mark: chapter_writing_{N} = completed
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Post-Processing Stage:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”Œâ”€ Extract Events
â”‚  Input:  chapter text
â”‚  Output: events[] with importance scores
â”‚  Save:   projects/{id}/outputs/events/events.json
â”‚
â”œâ”€ Extract Conflicts
â”‚  Input:  chapter text + existing conflicts
â”‚  Output: new_conflicts[], updated_conflicts[]
â”‚  Save:   projects/{id}/outputs/conflicts/conflicts.json
â”‚
â”œâ”€ Generate Summary
â”‚  Input:  chapter text
â”‚  Output: chapter summary (200-300 words)
â”‚  Save:   projects/{id}/outputs/summaries/summaries.json
â”‚
â”œâ”€ Extract New Entities
â”‚  Input:  chapter text + existing entities
â”‚  Output: new entities (characters, locations, etc.)
â”‚  Update: projects/{id}/outputs/entities/entities.json
â”‚
â””â”€ Update Super Summary
   Input:  all chapter summaries
   Output: overall story summary
   Save:   in checkpoint metadata
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Output Stage:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ“ Chapter file: .../chapters/chapter_{N}.txt
âœ“ Updated entities.json
âœ“ Updated events.json
âœ“ Updated conflicts.json
âœ“ Updated summaries.json
âœ“ Checkpoint updated
âœ“ Cost tracked
âœ“ LLM requests logged
```

---

## Core Components

### 1. Main Orchestrator (`main.py`)

**Class**: `StoryGenerator`

**Responsibilities**:
- Initialize all components
- Manage batch generation loop
- Coordinate between modules
- Handle checkpointing
- Track costs

**Key Methods**:
```python
__init__(config_path, project_id)
generate_story(num_batches, motif_id, genre)
generate_batch(batch_num, motif, user_suggestions)
_generate_chapter(chapter_num, outline, motif)
_prepare_chapter_context(chapter_num, outline, motif)
_prepare_batch_context(batch_num, user_suggestions)
```

**Initialization Flow**:
```
1. Load config from YAML
2. Create project directories
3. Initialize Logger
4. Initialize CostTracker
5. Initialize CheckpointManager
6. Initialize LLMClient
7. Initialize all processing modules
   - MotifLoader
   - OutlineGenerator
   - EntityManager
   - ChapterWriter
   - PostChapterProcessor
```

### 2. Configuration System (`config/config.yaml`)

**Structure**:
```yaml
default_llm:          # Default LLM settings
  provider: gemini
  model: gemini-2.5-flash
  temperature: 0.7
  max_tokens: 4000

task_configs:         # Task-specific overrides
  outline_generation: {...}
  entity_extraction: {...}
  chapter_writing: {...}
  event_extraction: {...}

story:                # Story parameters
  chapters_per_batch: 5
  target_words_per_chapter: 5000

paths:                # File paths
  projects_base_dir: "projects"
  motif_file: "data/motif.json"
  project_subdirs: {...}

logging:              # Logging config
  level: INFO
  log_prompts: true

cost_tracking:        # Pricing info
  pricing:
    gemini-2.5-pro: {input: 1.25, output: 5.00}
    gemini-2.5-flash: {input: 0.075, output: 0.30}
```

### 3. LLM Client (`src/llm_client.py`)

**Class**: `LLMClient`

**Responsibilities**:
- Wrap Gemini API calls
- Handle task-specific configurations
- Estimate tokens
- Calculate costs
- Log requests/responses

**Method Signature**:
```python
call(
    prompt: str,
    task_name: str = "default",
    system_message: Optional[str] = None,
    return_json: bool = False,
    batch_id: Optional[int] = None,
    chapter_id: Optional[int] = None,
    **kwargs
) -> Dict[str, Any]
```

**Returns**:
```python
{
    'response': str,          # LLM response text
    'tokens': {
        'input': int,
        'output': int,
        'total': int
    },
    'cost': float,           # USD
    'duration': float,       # seconds
    'model': str            # Model used
}
```

**Logging**:
- Main log: Via Logger.log_llm_call()
- Detailed log: Via Logger.log_llm_request() â†’ separate file
- Error log: Via Logger.log_llm_error() â†’ separate file

### 4. Checkpoint Manager (`src/checkpoint.py`)

**Class**: `CheckpointManager`

**Responsibilities**:
- Track completed steps
- Save/load checkpoint state
- Enable resume functionality
- Store metadata

**Checkpoint File Structure**:
```json
{
  "story_id": "story_001",
  "created_at": "2024-11-07T10:00:00",
  "last_updated": "2024-11-07T12:30:00",
  "current_batch": 2,
  "current_chapter": 7,
  "completed_steps": {
    "outline_generation_batch1": {
      "completed_at": "...",
      "metadata": {"num_chapters": 5}
    },
    "entity_extraction_batch_1": {...},
    "chapter_writing_1": {...},
    ...
  },
  "metadata": {
    "motif": {...},
    "super_summary": "...",
    ...
  }
}
```

**Key Methods**:
```python
is_step_completed(step_name, batch, chapter) -> bool
mark_step_completed(step_name, batch, chapter, metadata)
set_metadata(key, value)
get_metadata(key, default)
update_progress(batch, chapter)
```

---

## Module Details

### Module 1: Motif Loader

**File**: `src/motif_loader.py`

**Input**:
- `data/motif.json` - Collection of story templates

**Output**:
```python
{
    "id": "motif_001",
    "title": "TÃªn motif",
    "genre": "tu_tien",
    "protagonist": {...},
    "setting": {...},
    "conflict": {...},
    "theme": "..."
}
```

**Methods**:
```python
get_motif_by_id(motif_id) -> Dict
get_random_motif(genre=None) -> Dict
get_all_motifs() -> List[Dict]
```

### Module 2: Outline Generator

**File**: `src/outline_generator.py`

**Input for Initial Outline**:
- Motif object
- Batch number

**Input for Continuation Outline**:
```python
{
    'super_summary': str,        # Overall story summary
    'recent_summary': str,       # Last chapter summary
    'characters': List[Dict],    # Top characters
    'entities': List[Dict],      # Relevant entities
    'events': List[Dict],        # Important events
    'unresolved_conflicts': List[Dict],
    'user_suggestions': str      # Optional user input
}
```

**Output**: List of 5 chapter outlines
```python
[
    {
        "chapter_number": 1,
        "title": "ChÆ°Æ¡ng 1: Khá»Ÿi Ä‘áº§u",
        "summary": "TÃ³m táº¯t ngáº¯n gá»n",
        "key_events": [
            {
                "description": "Sá»± kiá»‡n",
                "order": 1,
                "purpose": "Setup/Plot/Character development"
            }
        ],
        "characters": [
            {
                "name": "Tráº§n PhÃ m",
                "role": "main",
                "development": "Giá»›i thiá»‡u nhÃ¢n váº­t"
            }
        ],
        "settings": ["Láº¡c Diá»‡p Tráº¥n", "Pháº¿ TÃ­ch Cá»•"],
        "conflicts": [
            {
                "type": "internal/external",
                "description": "...",
                "timeline": "immediate/batch/long_term"
            }
        ],
        "foreshadowing": ["Gá»£i Ã½ tÆ°Æ¡ng lai 1", "..."]
    },
    ...
]
```

**LLM Task**: `outline_generation`
- Model: gemini-2.5-flash
- Temperature: 0.8
- Max tokens: 4000

### Module 3: Entity Manager

**File**: `src/entity_manager.py`

**Input for Batch Extraction**:
- List of 5 chapter outlines
- Batch number

**Input for Chapter Extraction**:
- Chapter content text
- Chapter number
- Existing entities (for deduplication)

**Output**: Categorized entities
```python
{
    "characters": [
        {
            "name": "Tráº§n PhÃ m",
            "type": "character",
            "description": "giá»›i tÃ­nh: nam; ...; tiáº¿n trÃ¬nh: (c1)... â†’ (c5)...",
            "appear_in_chapters": [1, 2, 3, 4, 5]
        }
    ],
    "locations": [...],
    "items": [...],          # artifacts
    "spiritual_herbs": [...], # elixirs
    "beasts": [...],
    "techniques": [...],
    "factions": [...],
    "other": [...]
}
```

**Type Mapping** (Gemini response â†’ Storage):
```python
{
    'character': 'characters',
    'beast': 'beasts',
    'faction': 'factions',
    'artifact': 'items',
    'location': 'locations',
    'technique': 'techniques',
    'elixir': 'spiritual_herbs',
    'other': 'other'
}
```

**Key Methods**:
```python
extract_entities_from_outlines(outlines, batch_num) -> Dict
extract_entities_from_chapter(chapter_content, chapter_num) -> Dict
get_relevant_entities(chapter_outline, max_entities=20) -> List[Dict]
get_entity_by_name(name) -> Optional[Dict]
```

**LLM Task**: `entity_extraction`
- Model: gemini-2.5-flash
- Temperature: 0.3 (low for consistency)
- Max tokens: 3000

**JSON Parsing**:
- Uses `parse_json_from_response()` utility
- Handles markdown code blocks: ` ```json\n[...]\n``` `
- Supports both arrays and objects

### Module 4: Chapter Writer

**File**: `src/chapter_writer.py`

**Input**:
```python
chapter_outline = {
    "chapter_number": 5,
    "title": "...",
    "summary": "...",
    "key_events": [...],
    "characters": [...],
    "settings": [...],
    "conflicts": [...]
}

context = {
    'motif': {...},
    'related_entities': [...],
    'related_characters': [...],
    'related_events': [...],
    'recent_summaries': ["summary1", "summary2"],
    'super_summary': "Overall story summary",
    'previous_chapter_end': "Last 1000 chars of previous chapter"
}
```

**Output**:
- Chapter content text (5000+ words in Vietnamese)
- Saved to: `projects/{id}/outputs/chapters/chapter_{N}.txt`

**Prompt Structure**:
```
OUTLINE CHÆ¯Æ NG {N}: {title}
â”œâ”€ TÃ³m táº¯t
â”œâ”€ Sá»± kiá»‡n chÃ­nh
â”œâ”€ NhÃ¢n váº­t
â”œâ”€ Äá»‹a Ä‘iá»ƒm
â””â”€ MÃ¢u thuáº«n

NGá»® Cáº¢NH TRUYá»†N:
â”œâ”€ Motif gá»‘c
â”œâ”€ TÃ³m táº¯t tá»•ng thá»ƒ
â”œâ”€ TÃ³m táº¯t chÆ°Æ¡ng gáº§n Ä‘Ã¢y
â”œâ”€ Káº¿t chÆ°Æ¡ng trÆ°á»›c
â”œâ”€ NhÃ¢n váº­t liÃªn quan
â”œâ”€ Sá»± kiá»‡n quan trá»ng
â””â”€ Entity liÃªn quan

YÃŠU Cáº¦U VIáº¾T:
- Äá»™ dÃ i: ~5000 tá»«
- Phong cÃ¡ch: Tu tiÃªn/kiáº¿m hiá»‡p
- MiÃªu táº£ chi tiáº¿t
- Äá»‘i thoáº¡i tá»± nhiÃªn
- LiÃªn káº¿t máº¡ch truyá»‡n
```

**LLM Task**: `chapter_writing`
- Model: gemini-2.5-pro (high quality)
- Temperature: 0.85 (creative)
- Max tokens: 8000 (long output)

**Key Methods**:
```python
write_chapter(chapter_outline, context) -> str
get_chapter_end(chapter_num, last_chars=1000) -> str
_create_writing_prompt(outline, context) -> str
```

### Module 5: Post-Processor

**File**: `src/post_processor.py`

**Responsibilities**:
1. Extract events from chapter
2. Extract/update conflicts
3. Generate chapter summary
4. Update super summary

**5.1 Event Extraction**

**Input**: Chapter content + chapter number

**Output**: List of events
```python
[
    {
        "chapter": 5,
        "description": "Tráº§n PhÃ m Ä‘á»™t phÃ¡ Luyá»‡n KhÃ­ táº§ng 3",
        "importance": 0.9,  # 0-1 scale
        "characters_involved": ["Tráº§n PhÃ m", "Linh Há»“n SÆ° Phá»¥"],
        "location": "Pháº¿ TÃ­ch Cá»•",
        "consequences": "TÄƒng sá»©c máº¡nh, thu hÃºt sá»± chÃº Ã½"
    },
    ...
]
```

**LLM Task**: `event_extraction`
- Model: gemini-2.5-flash
- Temperature: 0.3
- Max tokens: 2000

**5.2 Conflict Extraction**

**Input**: Chapter content + existing conflicts

**Output**:
```python
{
    "new_conflicts": [
        {
            "id": "conflict_ch5_1",
            "type": "external",
            "description": "...",
            "introduced_chapter": 5,
            "timeline": "short_term",  # immediate/batch/short/medium/long/epic
            "status": "active"
        }
    ],
    "updated_conflicts": [
        {
            "id": "conflict_ch3_2",
            "status": "resolved",
            "resolution_chapter": 5
        }
    ]
}
```

**Conflict Timeline Categories**:
```python
{
    "immediate": 1 chapter,
    "batch": 5 chapters,
    "short_term": 10 chapters,
    "medium_term": 30 chapters,
    "long_term": 100 chapters,
    "epic": 300 chapters
}
```

**5.3 Summary Generation**

**Input**: Chapter content

**Output**:
```python
{
    "chapter": 5,
    "summary": "200-300 word summary in Vietnamese",
    "key_points": ["Point 1", "Point 2", "Point 3"]
}
```

**5.4 Super Summary**

Periodically updated overall story summary based on all chapter summaries.

**Key Methods**:
```python
process_chapter(chapter_content, chapter_num) -> Dict
extract_events(chapter_content, chapter_num) -> List[Dict]
extract_conflicts(chapter_content, chapter_num) -> Tuple[List, List]
generate_summary(chapter_content, chapter_num) -> str
update_super_summary(chapter_num) -> str
get_unresolved_conflicts() -> List[Dict]
get_recent_summaries(count=2) -> List[str]
```

---

## File Structure

### Project Directory Layout

```
projects/
â””â”€â”€ {project_id}/           # e.g., story_001
    â”œâ”€â”€ outputs/            # All generated content
    â”‚   â”œâ”€â”€ chapters/
    â”‚   â”‚   â”œâ”€â”€ chapter_1.txt
    â”‚   â”‚   â”œâ”€â”€ chapter_2.txt
    â”‚   â”‚   â””â”€â”€ ...
    â”‚   â”œâ”€â”€ outlines/
    â”‚   â”‚   â”œâ”€â”€ batch_1_outline.json
    â”‚   â”‚   â”œâ”€â”€ batch_2_outline.json
    â”‚   â”‚   â””â”€â”€ ...
    â”‚   â”œâ”€â”€ entities/
    â”‚   â”‚   â””â”€â”€ entities.json      # All entities, categorized
    â”‚   â”œâ”€â”€ events/
    â”‚   â”‚   â””â”€â”€ events.json        # All events with importance
    â”‚   â”œâ”€â”€ conflicts/
    â”‚   â”‚   â””â”€â”€ conflicts.json     # All conflicts with status
    â”‚   â”œâ”€â”€ summaries/
    â”‚   â”‚   â””â”€â”€ summaries.json     # Per-chapter summaries
    â”‚   â””â”€â”€ cost_summary.json      # Final cost report
    â”‚
    â”œâ”€â”€ checkpoints/
    â”‚   â””â”€â”€ {project_id}_checkpoint.json
    â”‚
    â””â”€â”€ logs/
        â”œâ”€â”€ StoryGenerator_YYYYMMDD_HHMMSS.log  # Main log
        â””â”€â”€ llm_requests/   # Detailed LLM request logs
            â”œâ”€â”€ outline_generation_batch001_20241107_120000_123456.txt
            â”œâ”€â”€ entity_extraction_batch001_20241107_120530_234567.txt
            â”œâ”€â”€ chapter_writing_chapter001_20241107_121000_345678.txt
            â”œâ”€â”€ event_extraction_chapter001_20241107_122000_456789.txt
            â””â”€â”€ ...
```

### LLM Request Log Format

**Filename Pattern**:
```
{task_name}_{context}_{timestamp}_{random}.txt
```

Examples:
- `outline_generation_batch001_20241107_120000_123456.txt`
- `entity_extraction_batch002_20241107_140000_234567.txt`
- `chapter_writing_chapter005_20241107_160000_345678.txt`

**Content Format**:
```
========================================
LLM Request Log
========================================
Timestamp: 2024-11-07 12:00:00.123456
Task: outline_generation
Batch: 1
Chapter: None
Model: gemini-2.5-flash

========================================
System Prompt:
========================================
{system_prompt}

========================================
User Prompt:
========================================
{user_prompt}

========================================
Response:
========================================
{response}

========================================
Metrics:
========================================
Input Tokens: 3745
Output Tokens: 2269
Total Tokens: 6014
Cost: $0.0010
Duration: 34.73s
========================================
```

---

## Input/Output Specifications

### CLI Input

```bash
python main.py \
  --project-id story_001 \
  --batches 3 \
  --motif-id motif_cultivation_001 \
  --genre tu_tien \
  --config config/config.yaml
```

**Parameters**:
- `--project-id`: Unique identifier (default: `story_001`)
- `--batches`: Number of 5-chapter batches (default: `1`)
- `--motif-id`: Specific motif to use (optional)
- `--genre`: Filter motifs by genre (optional)
- `--config`: Config file path (default: `config/config.yaml`)

### Input Files

**1. Motif File** (`data/motif.json`)
```json
[
    {
        "id": "motif_001",
        "title": "Tá»« pháº¿ tÃ i Ä‘áº¿n Ä‘á»‰nh cao tu luyá»‡n",
        "genre": "tu_tien",
        "protagonist": {
            "background": "Thiáº¿u niÃªn bá»‹ coi lÃ  pháº¿ tÃ i",
            "starting_power": "weak",
            "unique_trait": "CÃ³ báº£o váº­t áº©n giáº¥u"
        },
        "setting": {
            "world": "Tu tiÃªn giá»›i",
            "initial_location": "LÃ ng nhá» háº»o lÃ¡nh"
        },
        "conflict": {
            "internal": "VÆ°á»£t qua giá»›i háº¡n báº£n thÃ¢n",
            "external": "Äá»‘i Ä‘áº§u káº» Ä‘á»‹ch máº¡nh máº½"
        },
        "theme": "Nghá»‹ lá»±c, phÃ¡t triá»ƒn báº£n thÃ¢n"
    }
]
```

**2. Config File** (`config/config.yaml`)
```yaml
default_llm:
  provider: "gemini"
  model: "gemini-2.5-flash"
  temperature: 0.7
  max_tokens: 4000
  keys_file: "auth_files/keys.txt"

task_configs:
  chapter_writing:
    model: "gemini-2.5-pro"
    temperature: 0.85
    max_tokens: 8000
  
story:
  chapters_per_batch: 5
  target_words_per_chapter: 5000

paths:
  projects_base_dir: "projects"
  motif_file: "data/motif.json"
```

**3. API Keys File** (`auth_files/keys.txt`)
```
API_KEY_1
API_KEY_2
API_KEY_3
```
One key per line. System will randomly rotate through keys.

### Output Files

**1. Chapter Files**
- Path: `projects/{id}/outputs/chapters/chapter_{N}.txt`
- Format: Plain text, UTF-8
- Content: 5000+ words of Vietnamese story text

**2. Outline Files**
- Path: `projects/{id}/outputs/outlines/batch_{N}_outline.json`
- Format: JSON with 5 chapter outlines

**3. Entities File**
- Path: `projects/{id}/outputs/entities/entities.json`
- Format: Categorized entity dictionary
```json
{
  "characters": [{...}],
  "locations": [{...}],
  "items": [{...}],
  "techniques": [{...}],
  ...
}
```

**4. Events File**
- Path: `projects/{id}/outputs/events/events.json`
- Format: Array of event objects with importance scores

**5. Conflicts File**
- Path: `projects/{id}/outputs/conflicts/conflicts.json`
- Format: Array of conflict objects with status tracking

**6. Summaries File**
- Path: `projects/{id}/outputs/summaries/summaries.json`
- Format: Array of per-chapter summaries

**7. Checkpoint File**
- Path: `projects/{id}/checkpoints/{id}_checkpoint.json`
- Format: State object with completed steps

**8. Cost Summary**
- Path: `projects/{id}/outputs/cost_summary.json`
- Format: Breakdown of API costs
```json
{
  "total_cost": 12.45,
  "total_tokens": {
    "input": 150000,
    "output": 80000,
    "total": 230000
  },
  "total_calls": 45,
  "by_model": {...},
  "by_step": {...}
}
```

**9. Log Files**
- Main: `projects/{id}/logs/StoryGenerator_YYYYMMDD_HHMMSS.log`
- LLM Requests: `projects/{id}/logs/llm_requests/*.txt`

---

## API Integration

### Gemini API Integration

**Provider**: Google Gemini via `gemini_client_pool.py`

**Models Used**:
1. **gemini-2.5-flash** (default)
   - Use case: Outline, entity extraction, event extraction
   - Pricing: $0.075/1M input tokens, $0.30/1M output tokens
   - Speed: Fast
   - Quality: Good for structured tasks

2. **gemini-2.5-pro**
   - Use case: Chapter writing
   - Pricing: $1.25/1M input tokens, $5.00/1M output tokens
   - Speed: Slower
   - Quality: Excellent for creative writing

**API Call Flow**:
```
LLMClient.call()
    â†“
Get task config (model, temperature, max_tokens)
    â†“
gemini_call_text_free() or gemini_call_json_free()
    â†“
Load random API key from pool
    â†“
Construct Gemini API request
    â†“
POST https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent
    â†“
Parse response
    â†“
Extract JSON from markdown if needed (```json\n...\n```)
    â†“
Return to LLMClient
    â†“
Log request/response
Calculate cost
Update cost tracker
    â†“
Return result to caller
```

**Request Format**:
```json
{
  "contents": [{
    "parts": [{
      "text": "{system_prompt}\n\n{user_prompt}"
    }]
  }],
  "generationConfig": {
    "temperature": 0.7,
    "maxOutputTokens": 4000
  }
}
```

**Response Format**:
```json
{
  "candidates": [{
    "content": {
      "parts": [{
        "text": "Response text (may be wrapped in ```json\n...\n```)"
      }]
    }
  }],
  "usageMetadata": {
    "promptTokenCount": 1000,
    "candidatesTokenCount": 500,
    "totalTokenCount": 1500
  }
}
```

**JSON Parsing**:
- Gemini often wraps JSON in markdown code blocks
- System uses `parse_json_from_response()` utility
- Pattern: ` ```json\n{...}\n``` ` or ` ```json\n[...]\n``` `
- Supports both objects and arrays

**Error Handling**:
```python
try:
    response = gemini_call_text_free(...)
except Exception as e:
    logger.log_llm_error(
        task_name=task_name,
        error=str(e),
        prompts=prompts,
        batch_id=batch_id,
        chapter_id=chapter_id
    )
    raise
```

**Rate Limiting**:
- Key rotation: Multiple keys rotated randomly
- Sleep: 0.1s between requests (configurable)
- Retry: Automatic retry on transient errors

---

## Checkpoint & Recovery

### Checkpoint Mechanism

**Purpose**: Enable stopping and resuming story generation at any point

**Checkpoint File**: `projects/{id}/checkpoints/{id}_checkpoint.json`

**Structure**:
```json
{
  "story_id": "story_001",
  "created_at": "2024-11-07T10:00:00",
  "last_updated": "2024-11-07T12:30:00",
  "current_batch": 2,
  "current_chapter": 7,
  "completed_steps": {
    "outline_generation_batch1": {
      "completed_at": "2024-11-07T10:05:00",
      "metadata": {"num_chapters": 5}
    },
    "entity_extraction_batch_1": {
      "completed_at": "2024-11-07T10:10:00",
      "metadata": {"total_entities": 12}
    },
    "chapter_writing_1": {
      "completed_at": "2024-11-07T10:25:00",
      "metadata": {"title": "ChÆ°Æ¡ng 1: Khá»Ÿi Ä‘áº§u", "word_count": 5234}
    },
    "event_extraction_1": {...},
    "conflict_extraction_1": {...},
    "summary_generation_1": {...},
    ...
  },
  "metadata": {
    "motif": {...},
    "super_summary": "Overall story summary updated periodically",
    ...
  }
}
```

**Step Naming Convention**:
- Batch-level: `{step_name}_batch{N}`
  - Example: `outline_generation_batch2`, `entity_extraction_batch_3`
- Chapter-level: `{step_name}_{N}`
  - Example: `chapter_writing_5`, `event_extraction_7`
- Mixed: `{step_name}_batch{B}_ch{C}`

**Checkpoint Flow**:
```
Before each major step:
    â†“
Check: is_step_completed(step_name, batch, chapter)
    â†“
If completed: Skip and load from file
    â†“
If not completed: Execute step
    â†“
After completion: mark_step_completed(step_name, batch, chapter, metadata)
    â†“
Save checkpoint to disk
```

**Resume Behavior**:
```
User stops at Chapter 7
    â†“
Restart: python main.py --project-id story_001 --batches 3
    â†“
System loads checkpoint
    â†“
Finds Chapter 1-7 completed
    â†“
Resumes from Chapter 8
    â†“
Continues until all batches done
```

**Metadata Usage**:
- Store motif for reference in later batches
- Store super_summary for context
- Store custom flags or state

---

## Cost Tracking

### Cost Tracking System

**Purpose**: Monitor and report API costs for budget control

**Components**:
1. **CostTracker** (`src/utils.py`)
2. **LLMClient** integration
3. **Pricing config** in `config.yaml`

**Data Structure**:
```python
{
    "total_cost": 12.45,  # USD
    "total_tokens": {
        "input": 150000,
        "output": 80000,
        "total": 230000
    },
    "total_calls": 45,
    "by_model": {
        "gemini-2.5-flash": {
            "calls": 35,
            "input_tokens": 120000,
            "output_tokens": 50000,
            "cost": 10.50
        },
        "gemini-2.5-pro": {
            "calls": 10,
            "input_tokens": 30000,
            "output_tokens": 30000,
            "cost": 1.95
        }
    },
    "by_step": {
        "outline_generation": {
            "calls": 3,
            "tokens": 25000,
            "cost": 1.20
        },
        "chapter_writing": {
            "calls": 10,
            "tokens": 180000,
            "cost": 8.50
        },
        "entity_extraction": {...},
        "event_extraction": {...},
        ...
    }
}
```

**Pricing Configuration** (`config.yaml`):
```yaml
cost_tracking:
  enabled: true
  pricing:
    gemini-2.5-pro:
      input: 1.25    # USD per 1M tokens
      output: 5.00
    gemini-2.5-flash:
      input: 0.075
      output: 0.30
```

**Cost Calculation**:
```python
def _calculate_gemini_cost(model, input_tokens, output_tokens):
    if 'pro' in model.lower():
        input_cost_per_1m = 1.25
        output_cost_per_1m = 5.00
    else:
        input_cost_per_1m = 0.075
        output_cost_per_1m = 0.30
    
    input_cost = (input_tokens / 1_000_000) * input_cost_per_1m
    output_cost = (output_tokens / 1_000_000) * output_cost_per_1m
    
    return input_cost + output_cost
```

**Tracking Flow**:
```
LLM API call completes
    â†“
Estimate tokens (input + output)
    â†“
Calculate cost using pricing config
    â†“
CostTracker.add_call(model, input_tokens, output_tokens, step, duration)
    â†“
Update totals and breakdowns
    â†“
At end: CostTracker.save_summary(cost_file)
```

**Real-time Logging**:
```
INFO - LLM call: model=gemini-2.5-flash, task=entity_extraction
INFO - Tokens: 3745 input, 2269 output (6014 total)
INFO - Cost: $0.0010, Duration: 34.73s
```

**Final Summary** (`cost_summary.json`):
```json
{
  "total_cost": 12.45,
  "total_tokens": {
    "input": 150000,
    "output": 80000,
    "total": 230000
  },
  "total_calls": 45,
  "by_model": {...},
  "by_step": {...},
  "summary": {
    "chapters_written": 15,
    "cost_per_chapter": 0.83,
    "tokens_per_chapter": 15333
  }
}
```

---

## Performance Considerations

### Token Estimation

**Current Method**: Character-based estimation
```python
def _estimate_tokens(text: str) -> int:
    # Vietnamese: ~2.5 chars per token
    return int(len(text) / 2.5)
```

**Accuracy**: Â±15% (acceptable for cost estimation)

**Future**: Use tiktoken library for exact counts

### API Latency

**Average Response Times**:
- Outline generation (flash): 15-30s
- Entity extraction (flash): 20-40s
- Chapter writing (pro): 60-120s
- Event extraction (flash): 10-20s

**Bottlenecks**:
- Chapter writing is slowest (large output)
- Sequential processing (no parallelization yet)

**Optimization Opportunities**:
1. Parallel chapter writing (if independent)
2. Batch API calls for entity extraction
3. Caching for repeated prompts
4. Stream output for real-time feedback

### Storage

**Typical Project Size** (15 chapters):
- Chapters: ~750KB (15 Ã— 50KB)
- Outlines: ~50KB
- Entities: ~30KB
- Events: ~20KB
- Conflicts: ~15KB
- Summaries: ~20KB
- Checkpoints: ~10KB
- Logs: ~500KB
- LLM request logs: ~2MB
- **Total**: ~3.4MB per project

**Scaling**: 100 projects = ~340MB (negligible)

---

## Error Handling

### Error Categories

**1. API Errors**
- Network timeout
- Invalid API key
- Rate limit exceeded
- Content policy violation

**Handling**:
```python
try:
    response = gemini_call_text_free(...)
except Exception as e:
    logger.log_llm_error(...)
    raise
```

**Logging**: Full prompts saved to separate error log file

**2. JSON Parsing Errors**
- Malformed JSON from LLM
- Missing markdown code blocks
- Unexpected format

**Handling**:
```python
try:
    data = parse_json_from_response(response)
except json.JSONDecodeError as e:
    logger.error(f"JSON parsing error: {e}")
    logger.error(f"Response preview: {response[:500]}")
    return default_value
```

**3. File I/O Errors**
- Permission denied
- Disk full
- Path not found

**Handling**: Ensure directories exist before writing

**4. Checkpoint Errors**
- Corrupted checkpoint file
- Version mismatch

**Handling**: Backup checkpoints before overwriting

### Retry Strategy

**Not Implemented Yet** (Future Enhancement):
```python
@retry(max_attempts=3, backoff=2.0)
def call_llm_with_retry(...):
    ...
```

### Graceful Degradation

If a non-critical step fails (e.g., event extraction):
- Log the error
- Continue with default/empty value
- Mark step as completed (to avoid re-attempting)

---

## Testing

### Manual Testing

**Test Script**: `test_json_parsing.py`
```bash
python3 test_json_parsing.py
```

Tests:
- âœ“ Markdown wrapped array
- âœ“ Markdown wrapped object
- âœ“ Plain JSON array
- âœ“ Plain JSON object
- âœ“ Type mapping
- âœ“ Real Gemini response

### Integration Testing

**Full Pipeline Test**:
```bash
python main.py --project-id test_001 --batches 1 --motif-id motif_001
```

Verify:
1. All modules initialize
2. Motif loaded
3. Outline generated (5 chapters)
4. Entities extracted
5. Chapters written
6. Post-processing completed
7. Checkpoint saved
8. Cost tracked
9. Logs created

### Unit Testing

**Not Implemented Yet** (Future):
- Test each module independently
- Mock LLM responses
- Verify checkpoint logic
- Test JSON parsing edge cases

---

## Security Considerations

### API Key Management

**Current**:
- Keys stored in `auth_files/keys.txt` (plain text)
- Not committed to git (in `.gitignore`)
- Random rotation

**Recommendations**:
- Use environment variables
- Encrypt keys at rest
- Implement key rotation policy
- Monitor for leaked keys

### Input Validation

**Current**: Limited validation

**Future**:
- Validate motif structure
- Sanitize user input
- Limit prompt lengths
- Check for injection attempts

### Output Sanitization

**Content Policy**:
- Gemini has built-in content filters
- Check for blocked responses
- Handle policy violations gracefully

---

## Future Enhancements

### Planned Features

**1. Parallel Processing**
```python
# Write multiple chapters in parallel
with ThreadPoolExecutor(max_workers=3) as executor:
    futures = [executor.submit(write_chapter, outline) for outline in outlines]
    chapters = [f.result() for f in futures]
```

**2. Advanced Entity Linking**
- Track entity relationships
- Visualize entity graph
- Detect inconsistencies

**3. Quality Checks**
- Coherence scoring
- Fact consistency checking
- Character development tracking

**4. Interactive Mode**
```python
# Allow user to modify outline before writing
outline = generate_outline(motif)
outline = user_review(outline)  # Interactive prompt
chapters = write_chapters(outline)
```

**5. Multiple Output Formats**
- ePub generation
- PDF with formatting
- HTML web version

**6. Web Interface**
- Flask/FastAPI backend
- React frontend
- Real-time progress tracking
- Live preview

### Research Directions

**1. Fine-tuning**
- Fine-tune on Chinese wuxia/xianxia corpus
- Improve Vietnamese translation quality
- Customize for story genre

**2. Reinforcement Learning**
- Use user feedback to improve
- Rank outputs by quality
- Optimize for engagement

**3. Multi-model Ensemble**
- Combine outputs from multiple models
- Vote on best version
- Improve consistency

---

## Troubleshooting

### Common Issues

**Issue**: JSON parsing error
```
ERROR - JSON parsing error: Expecting value: line 1 column 1 (char 0)
```
**Solution**: Check LLM request log, verify response format
**Fix**: v1.3.1 added robust JSON parsing

**Issue**: Module import error
```
ModuleNotFoundError: No module named 'prompts'
```
**Solution**: Use correct import path `from src.prompts.extract_prompt`
**Fix**: v1.3.0 updated all imports

**Issue**: Checkpoint not resuming
```
Completed chapter 5 but system starts from chapter 1
```
**Solution**: Verify checkpoint file exists and is valid JSON
**Debug**: Check `completed_steps` keys match step names

**Issue**: High API costs
```
Generated 5 chapters, cost = $50
```
**Solution**: Check model config, use flash instead of pro where possible
**Optimize**: Reduce max_tokens, optimize prompts

**Issue**: Empty entity extraction
```
Entity extraction returned 0 entities
```
**Solution**: Check LLM response in log file
**Debug**: Verify prompt includes clear instructions

### Debug Mode

Enable verbose logging:
```yaml
# config.yaml
logging:
  level: DEBUG
  log_prompts: true
  log_responses: true
```

Check logs:
```bash
tail -f projects/story_001/logs/StoryGenerator_*.log
```

Inspect LLM requests:
```bash
cat projects/story_001/logs/llm_requests/entity_extraction_*.txt
```

---

## Appendix

### Glossary

- **Batch**: Group of 5 chapters
- **Checkpoint**: Saved state for resume
- **Entity**: Character, location, item, etc.
- **Event**: Important story occurrence
- **Conflict**: Unresolved tension/problem
- **Motif**: Story template/seed
- **Outline**: High-level chapter plan
- **Super Summary**: Overall story summary

### File Extensions

- `.json` - Structured data (entities, events, etc.)
- `.txt` - Plain text (chapters, logs)
- `.yaml` - Configuration
- `.py` - Python source code
- `.md` - Documentation (Markdown)

### Naming Conventions

**Files**:
- Lowercase with underscores: `chapter_writer.py`
- Descriptive: `entity_extraction_batch001_*.txt`

**Classes**:
- PascalCase: `StoryGenerator`, `EntityManager`

**Methods**:
- snake_case: `generate_outline()`, `extract_entities()`

**Variables**:
- snake_case: `chapter_num`, `entity_file`

### Version History

- **v1.0.0**: Initial release
- **v1.1.0**: Added checkpoint system
- **v1.2.0**: Added cost tracking
- **v1.3.0**: Project-based structure, detailed logging
- **v1.3.1**: Fixed JSON parsing for Gemini responses

---

## Contact & Support

**Repository**: story_writer_v2  
**Documentation**: `/root/test_writer/`  
**Issues**: Create GitHub issue  
**Updates**: Check `CHANGELOG.md`

---

**Last Updated**: 2024-11-07  
**Document Version**: 2.0  
**System Version**: 1.3.1

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Main Orchestrator                        â”‚
â”‚                       (main.py)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚               â”‚               â”‚
       â–¼               â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Core    â”‚    â”‚ Pipeline â”‚    â”‚  Post    â”‚
â”‚ Modules  â”‚    â”‚ Modules  â”‚    â”‚Processingâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ—ï¸ Core Modules

### 1. Utils (`src/utils.py`)

**TrÃ¡ch nhiá»‡m:**
- File I/O operations (JSON, text)
- Configuration management
- Logging system
- Cost tracking

**Key Classes:**
- `Logger`: Quáº£n lÃ½ logging vá»›i multi-handler (file + console)
- `CostTracker`: Theo dÃµi chi phÃ­ API vÃ  token usage

**Features:**
- Automatic directory creation
- UTF-8 encoding support
- Structured logging vá»›i metadata

### 2. Checkpoint Manager (`src/checkpoint.py`)

**TrÃ¡ch nhiá»‡m:**
- LÆ°u/load checkpoint state
- Theo dÃµi bÆ°á»›c Ä‘Ã£ hoÃ n thÃ nh
- Há»— trá»£ resume tá»« giÃ¡n Ä‘oáº¡n

**Data Structure:**
```json
{
  "story_id": "story_001",
  "current_batch": 2,
  "current_chapter": 7,
  "completed_steps": {
    "outline_generation_batch1": {
      "completed_at": "2025-01-07T14:30:22",
      "metadata": {...}
    }
  },
  "metadata": {
    "motif": {...},
    "super_summary": "..."
  }
}
```

**Key Methods:**
- `is_step_completed()`: Kiá»ƒm tra bÆ°á»›c Ä‘Ã£ hoÃ n thÃ nh chÆ°a
- `mark_step_completed()`: ÄÃ¡nh dáº¥u bÆ°á»›c hoÃ n thÃ nh
- `set_metadata()`: LÆ°u metadata global

### 3. LLM Client (`src/llm_client.py`)

**TrÃ¡ch nhiá»‡m:**
- Wrapper cho OpenAI API
- Token counting
- Cost calculation
- Task-specific configuration

**Features:**
- Tá»± Ä‘á»™ng chá»n config theo task
- Token counting vá»›i tiktoken
- Error handling vÃ  retry logic
- Logging Ä‘áº§y Ä‘á»§ prompt/response

**Call Flow:**
```
User Code â†’ LLMClient.call()
    â†“
1. Load task config
2. Count input tokens
3. Call OpenAI API
4. Calculate cost
5. Log everything
6. Return result
```

## ğŸ”„ Pipeline Modules

### 1. Motif Loader (`src/motif_loader.py`)

**Input:** `data/motif.json`

**Output:** Selected motif object

**Features:**
- Random selection
- Genre filtering
- ID-based lookup

### 2. Outline Generator (`src/outline_generator.py`)

**Modes:**
- **Initial**: Táº¡o outline batch Ä‘áº§u tá»« motif
- **Continuation**: Táº¡o outline batch tiáº¿p vá»›i context

**Input (Initial):**
- Motif

**Input (Continuation):**
- Super summary
- Recent summaries
- Characters, entities, events
- Unresolved conflicts
- User suggestions

**Output:**
```json
{
  "batch": 1,
  "chapters": [
    {
      "chapter_number": 1,
      "title": "...",
      "summary": "...",
      "key_events": [...],
      "characters": [...],
      "conflicts": [...],
      "settings": [...],
      "foreshadowing": [...]
    }
  ]
}
```

**Prompt Strategy:**
- Detailed requirements trong prompt
- JSON format enforcement
- Examples vÃ  constraints

### 3. Entity Manager (`src/entity_manager.py`)

**Entity Categories:**
1. Characters (nhÃ¢n váº­t)
2. Locations (Ä‘á»‹a Ä‘iá»ƒm)
3. Items (váº­t pháº©m)
4. Spiritual Herbs (linh dÆ°á»£c)
5. Beasts (yÃªu thÃº)
6. Techniques (cÃ´ng phÃ¡p)
7. Factions (tháº¿ lá»±c)

**Features:**
- Extraction tá»« outline
- Extraction tá»« chapter content
- Merge vá»›i duplicate detection
- Relevant entity selection

**Algorithm - Get Relevant Entities:**
```python
1. Láº¥y characters xuáº¥t hiá»‡n trong chapter
2. Láº¥y locations trong settings
3. Láº¥y entities liÃªn káº¿t vá»›i characters
4. Sort vÃ  limit theo max_entities
```

**Storage:**
```json
{
  "characters": [
    {
      "name": "LÃ½ Thanh VÃ¢n",
      "description": "...",
      "cultivation_level": "Kim Äan ká»³",
      "abilities": [...],
      "relationships": [...]
    }
  ],
  "locations": [...],
  ...
}
```

### 4. Chapter Writer (`src/chapter_writer.py`)

**Context Selection Algorithm:**

```python
def prepare_context():
    1. Get chapter outline
    2. Get relevant entities (from outline)
    3. Get related characters (by name)
    4. Get related events (by characters involved)
    5. Get recent summaries (last 2)
    6. Get super summary
    7. Get last 1000 chars of previous chapter
    8. Get motif
    
    return comprehensive_context
```

**Writing Prompt Structure:**
1. **Chapter Outline**: Title, summary, events, characters, conflicts
2. **Context**: Motif, summaries, previous ending
3. **Reference Data**: Characters, events, entities
4. **Requirements**: Length, structure, style
5. **Constraints**: Consistency, character development

**Output:**
- `output/chapters/chapter_XXX.txt`: Ná»™i dung
- `output/chapters/chapter_XXX_meta.json`: Metadata

## ğŸ“Š Post-Processing Modules

### Post Processor (`src/post_processor.py`)

**Tasks After Each Chapter:**

1. **Event Extraction**
   - Chá»‰ events quan trá»ng (importance: 0-1)
   - Characters involved
   - Consequences

2. **Conflict Extraction**
   - New conflicts
   - Updated conflicts (status changes)
   - Timeline classification

3. **Summary Generation**
   - 150-250 tá»«
   - Key events
   - Important developments

4. **Super Summary Update**
   - Ultra-condensed (100-200 tá»«)
   - Entire story so far
   - Incremental update

**Conflict Tracking:**

```python
Conflict Structure:
{
    "id": "conflict_ch3_5",
    "description": "...",
    "type": "external",
    "timeline": "batch",
    "status": "active",  # or "resolved"
    "introduced_chapter": 3,
    "resolution_chapter": null,
    "characters_involved": [...]
}
```

**Timeline Categories:**
- `immediate`: 1 chapter
- `batch`: 5 chapters
- `short_term`: 10 chapters
- `medium_term`: 30 chapters
- `long_term`: 100 chapters
- `epic`: 300 chapters

## ğŸ”€ Data Flow

### Complete Generation Flow

```
START
  â†“
[1] Load Motif
  â†“
[2] Generate Outline (Batch 1)
  â†“
[3] Extract Entities from Outline
  â†“
â”Œâ”€[4] FOR each chapter:
â”‚   â†“
â”‚   [4a] Prepare Context
â”‚   â†“
â”‚   [4b] Write Chapter Content
â”‚   â†“
â”‚   [4c] Extract New Entities
â”‚   â†“
â”‚   [4d] Extract Events
â”‚   â†“
â”‚   [4e] Extract Conflicts
â”‚   â†“
â”‚   [4f] Generate Summary
â”‚   â†“
â”‚   [4g] Update Super Summary
â”‚   â†“
â””â”€â”€ [4h] Save Checkpoint
  â†“
[5] Batch Complete?
  â†“ No
[6] Generate Outline (Next Batch)
  â†“ (with expanded context)
  â””â”€â†’ Go to [3]
  â†“ Yes
[7] Save Final Summary
  â†“
END
```

### Context Evolution

**Batch 1:**
```
Motif only
```

**Batch 2:**
```
Motif +
Super Summary +
Recent Summaries +
All Entities +
Important Events +
Unresolved Conflicts +
User Suggestions
```

**Batch N:**
```
Same as Batch 2, but:
- More entities accumulated
- More events tracked
- Conflicts resolved/evolved
- Richer super summary
```

## ğŸ—„ï¸ File Organization

### Output Structure

```
output/
â”œâ”€â”€ chapters/
â”‚   â”œâ”€â”€ chapter_001.txt          # Ná»™i dung chapter
â”‚   â”œâ”€â”€ chapter_001_meta.json    # Metadata
â”‚   â””â”€â”€ ...
â”œâ”€â”€ outlines/
â”‚   â”œâ”€â”€ batch_1_outline.json     # Outline batch 1
â”‚   â””â”€â”€ ...
â”œâ”€â”€ entities/
â”‚   â””â”€â”€ entities.json            # Global entity database
â”œâ”€â”€ events/
â”‚   â””â”€â”€ events.json              # All events vá»›i importance
â”œâ”€â”€ conflicts/
â”‚   â””â”€â”€ conflicts.json           # All conflicts vá»›i tracking
â”œâ”€â”€ summaries/
â”‚   â””â”€â”€ summaries.json           # All chapter summaries
â””â”€â”€ cost_summary.json            # Cost tracking
```

### Checkpoint Structure

```
checkpoints/
â””â”€â”€ story_001_checkpoint.json    # State cá»§a story_001
```

### Logs Structure

```
logs/
â””â”€â”€ StoryGenerator_YYYYMMDD_HHMMSS.log
```

## ğŸ”§ Extensibility Points

### 1. ThÃªm Entity Type Má»›i

```python
# src/entity_manager.py
def _load_entities():
    return {
        'characters': [],
        'locations': [],
        'new_type': [],  # ThÃªm type má»›i
        ...
    }
```

### 2. ThÃªm LLM Provider Má»›i

```python
# src/llm_client.py
class LLMClient:
    def __init__(self):
        if provider == 'openai':
            self.client = OpenAI()
        elif provider == 'anthropic':
            self.client = Anthropic()  # ThÃªm provider
```

### 3. Custom Prompt Templates

```python
# src/outline_generator.py
def _create_outline_prompt():
    # Sá»­a template prompt
    return custom_prompt
```

### 4. ThÃªm Post-Processing Task

```python
# src/post_processor.py
def process_chapter():
    # ThÃªm task má»›i
    new_data = extract_new_feature()
```

## ğŸ¯ Best Practices

### 1. Error Handling

Má»i LLM call Ä‘á»u cÃ³:
- Try-catch
- Logging
- Checkpoint save

### 2. Cost Control

- Token counting trÆ°á»›c khi call
- Cost estimate logging
- Configurable model per task

### 3. Resume Logic

```python
if checkpoint.is_step_completed(step):
    return load_from_file()
else:
    result = do_step()
    checkpoint.mark_completed(step)
    return result
```

### 4. Data Validation

- JSON parsing vá»›i fallback
- Required field checks
- Type validation

## ğŸ” Debugging

### Log Levels

- `DEBUG`: Táº¥t cáº£ chi tiáº¿t
- `INFO`: CÃ¡c bÆ°á»›c chÃ­nh
- `WARNING`: Issues khÃ´ng critical
- `ERROR`: Failures

### Checkpoint Inspection

```python
checkpoint = CheckpointManager('checkpoints', 'story_001')
print(checkpoint.state)
```

### Cost Tracking

```python
summary = cost_tracker.get_summary()
print(f"Total: ${summary['total_cost']}")
```

## ğŸ“ˆ Performance Optimization

### 1. Parallel Processing (Future)

```python
# CÃ³ thá»ƒ parallel nhiá»u chapters
with concurrent.futures.ThreadPoolExecutor() as executor:
    futures = [executor.submit(write_chapter, ch) for ch in chapters]
```

### 2. Caching

- Entity lookup cache
- Summary cache
- Conflict resolution cache

### 3. Batch API Calls

- Combine multiple extractions
- Reduce API call count

## ğŸ”’ Security

- API keys tá»« environment variables
- No hardcoded credentials
- Safe file operations

---

**Architecture Version:** 1.0
**Last Updated:** 2025-01-07
