# ƒê√°nh gi√° Logic Write Chapter cho Truy·ªán D√†i 300 Ch∆∞∆°ng

**Ng√†y:** 2025-11-07  
**Phi√™n b·∫£n h·ªá th·ªëng:** 1.3.1

## üìã T·ªïng quan

T√†i li·ªáu n√†y ƒë√°nh gi√° xem logic l·ª±a ch·ªçn entity v√† event hi·ªán t·∫°i c√≥ ƒë·ªß ch·∫∑t ch·∫Ω ƒë·ªÉ vi·∫øt truy·ªán d√†i 300 ch∆∞∆°ng hay kh√¥ng, v√† ƒë·ªÅ xu·∫•t c√°c t·ªëi ∆∞u h√≥a c·∫ßn thi·∫øt.

---

## üîç Ph√¢n t√≠ch hi·ªán tr·∫°ng

### 1. Entity Selection Logic

#### ‚úÖ ƒêi·ªÉm m·∫°nh hi·ªán t·∫°i

1. **Chapter-based filtering** (v1.3.1):
   - ƒê√£ c√≥ `appear_in_chapters` field ƒë·ªÉ track entity xu·∫•t hi·ªán ·ªü ch∆∞∆°ng n√†o
   - Filter entities theo chapter number trong `_filter_entities_by_chapter()`
   - Gi·∫£m 40-65% token consumption

2. **Category-based organization**:
   - Ph√¢n lo·∫°i r√µ r√†ng: characters, locations, items, techniques, beasts, factions
   - D·ªÖ qu·∫£n l√Ω v√† truy xu·∫•t

3. **Merge mechanism**:
   - T·ª± ƒë·ªông merge entities tr√πng l·∫∑p
   - Track descriptions qua nhi·ªÅu chapters

#### ‚ùå V·∫•n ƒë·ªÅ cho truy·ªán 300 ch∆∞∆°ng

**V·∫•n ƒë·ªÅ 1: Kh√¥ng c√≥ Recency Weight**

```python
# Hi·ªán t·∫°i trong ChapterWriter._get_entities_from_outline()
if chapter_num in entity.get('appear_in_chapters', []):
    full_entities.append(entity)  # Th√™m entity m√† kh√¥ng c√≥ scoring
```

**T√°c ƒë·ªông:**
- Entity t·ª´ chapter 1 v√† chapter 299 ƒë∆∞·ª£c ƒë·ªëi x·ª≠ nh∆∞ nhau khi vi·∫øt chapter 300
- Kh√¥ng ∆∞u ti√™n entities g·∫ßn ƒë√¢y h∆°n
- Context b·ªã lo√£ng v·ªõi th√¥ng tin c≈© kh√¥ng c√≤n relevant

**V·∫•n ƒë·ªÅ 2: Fixed Limits Kh√¥ng Adaptive**

```python
# Trong EntityManager.get_relevant_entities()
return relevant[:max_entities]  # Hard limit 20 entities
```

**T√°c ƒë·ªông:**
- 20 entities c√≥ th·ªÉ ƒë·ªß cho batch ƒë·∫ßu (ch∆∞∆°ng 1-5)
- Kh√¥ng ƒë·ªß cho chapter 250 v·ªõi h√†ng trƒÉm entities ƒë√£ xu·∫•t hi·ªán
- Kh√¥ng scale theo ƒë·ªô ph·ª©c t·∫°p c·ªßa story

**V·∫•n ƒë·ªÅ 3: Kh√¥ng c√≥ Importance Scoring**

```python
# Entities kh√¥ng c√≥ importance field
{
    "name": "L√Ω H·∫°o",
    "description": "...",
    "appear_in_chapters": [1, 5, 10, 50, 100]
    # Thi·∫øu: "importance": 0.9
    # Thi·∫øu: "last_mentioned_chapter": 100
    # Thi·∫øu: "mention_frequency": 0.8
}
```

**T√°c ƒë·ªông:**
- Kh√¥ng ph√¢n bi·ªát ƒë∆∞·ª£c nh√¢n v·∫≠t ch√≠nh vs nh√¢n v·∫≠t ph·ª•
- Entity xu·∫•t hi·ªán 1 l·∫ßn = entity xu·∫•t hi·ªán 100 l·∫ßn
- Kh√¥ng th·ªÉ prioritize khi context ƒë·∫ßy

**V·∫•n ƒë·ªÅ 4: Kh√¥ng c√≥ Sliding Window**

```python
# L·∫•y t·∫•t c·∫£ entities trong appear_in_chapters
# Kh√¥ng c√≥ focus v√†o chapters g·∫ßn ƒë√¢y
```

**T√°c ƒë·ªông:**
- Khi ·ªü chapter 250, v·∫´n load entities t·ª´ chapter 1-5
- Context window tr√†n v·ªõi th√¥ng tin c≈©
- Chi ph√≠ token tƒÉng kh√¥ng c·∫ßn thi·∫øt

---

### 2. Event Selection Logic

#### ‚úÖ ƒêi·ªÉm m·∫°nh hi·ªán t·∫°i

1. **Importance scoring** (0-1):
   - Events c√≥ importance score
   - ƒê∆∞·ª£c sort theo importance

2. **Characters/entities linking**:
   - Track characters_involved v√† entities_involved
   - Filter theo nh√¢n v·∫≠t trong outline

#### ‚ùå V·∫•n ƒë·ªÅ cho truy·ªán 300 ch∆∞∆°ng

**V·∫•n ƒë·ªÅ 1: No Recency Consideration**

```python
# Trong main.py._get_relevant_events()
all_events = sorted(
    self.post_processor.events,
    key=lambda x: x.get('importance', 0),  # Ch·ªâ sort theo importance
    reverse=True
)
```

**T√°c ƒë·ªông:**
- Event importance=0.9 t·ª´ chapter 10 ƒë∆∞·ª£c ∆∞u ti√™n h∆°n event importance=0.8 t·ª´ chapter 298
- Kh√¥ng ph√π h·ª£p v·ªõi narrative flow
- Context b·ªã l·∫•n √°t b·ªüi historical events

**V·∫•n ƒë·ªÅ 2: Fixed Limit Without Adaptation**

```python
return relevant[:10]  # Top 10 relevant events - fixed
```

**T√°c ƒë·ªông:**
- 10 events kh√¥ng ƒë·ªß th·ªÉ hi·ªán story arc ph·ª©c t·∫°p ·ªü chapter 200
- C√≥ th·ªÉ b·ªè s√≥t events quan tr·ªçng g·∫ßn ƒë√¢y

**V·∫•n ƒë·ªÅ 3: No Decay Mechanism**

```python
# Events kh√¥ng c√≥ decay theo th·ªùi gian
# Event t·ª´ 200 chapters tr∆∞·ªõc v·∫´n c√≥ importance nguy√™n b·∫£n
```

**T√°c ƒë·ªông:**
- Old events gi·ªØ importance cao m√£i m√£i
- Kh√¥ng ph·∫£n √°nh s·ª± thay ƒë·ªïi c·ªßa narrative
- Context pollution

**V·∫•n ƒë·ªÅ 4: No Event Relationship Tracking**

```python
# Kh√¥ng track event n√†o d·∫´n ƒë·∫øn event n√†o
# Kh√¥ng c√≥ causal chain
{
    "description": "Tr·∫≠n chi·∫øn X",
    "importance": 0.9,
    "chapter": 150
    # Thi·∫øu: "causes": [event_id_1, event_id_2]
    # Thi·∫øu: "caused_by": [event_id_0]
}
```

**T√°c ƒë·ªông:**
- Kh√¥ng th·ªÉ ch·ªçn events theo m·∫°ch nh√¢n qu·∫£
- M·∫•t logic li√™n k·∫øt gi·ªØa events

---

### 3. Conflict Management Logic

#### ‚úÖ ƒêi·ªÉm m·∫°nh hi·ªán t·∫°i

1. **Timeline-based classification**:
   - immediate, batch, short_term, medium_term, long_term, epic
   - Ph√π h·ª£p cho planning truy·ªán d√†i

2. **Status tracking**:
   - active/resolved status
   - Resolution chapter tracking

3. **Conflict analysis trong OutlineGenerator**:
   - `_analyze_conflicts_for_batch()` ph√¢n t√≠ch conflicts n√†o c·∫ßn resolve
   - LLM-driven conflict planning

#### ‚ùå V·∫•n ƒë·ªÅ cho truy·ªán 300 ch∆∞∆°ng

**V·∫•n ƒë·ªÅ 1: Unbounded Conflict Accumulation**

```python
# Trong PostChapterProcessor.get_unresolved_conflicts()
return [c for c in self.conflicts if c.get('status') == 'active']
```

**T√°c ƒë·ªông:**
- ·ªû chapter 250, c√≥ th·ªÉ c√≥ 100+ active conflicts
- Kh√¥ng c√≥ automatic pruning
- Context overload

**V·∫•n ƒë·ªÅ 2: No Priority Scoring**

```python
# Conflicts kh√¥ng c√≥ priority field
{
    "id": "conflict_ch5_1",
    "timeline": "long_term",
    "status": "active"
    # Thi·∫øu: "priority": 0.8
    # Thi·∫øu: "stale_since_chapter": 200  # Kh√¥ng ti·∫øn tri·ªÉn t·ª´ chapter 200
}
```

**T√°c ƒë·ªông:**
- Kh√¥ng th·ªÉ prioritize conflicts quan tr·ªçng
- Conflicts l·∫∑p ƒëi l·∫∑p l·∫°i kh√¥ng ƒë∆∞·ª£c gi·∫£i quy·∫øt

**V·∫•n ƒë·ªÅ 3: Timeline Kh√¥ng Adaptive**

```python
# Timeline definitions c·ªë ƒë·ªãnh
"epic": 300 chapters  # C·ªë ƒë·ªãnh, kh√¥ng scale
```

**T√°c ƒë·ªông:**
- N·∫øu story > 300 chapters th√¨ sao?
- Kh√¥ng flexible v·ªõi story length

**V·∫•n ƒë·ªÅ 4: No Arc-based Grouping**

```python
# Conflicts kh√¥ng ƒë∆∞·ª£c group theo story arc
# T·∫•t c·∫£ conflicts treated equally
```

**T√°c ƒë·ªông:**
- Kh√≥ qu·∫£n l√Ω conflicts trong c√°c arc kh√°c nhau
- Kh√¥ng th·ªÉ focus v√†o current arc

---

### 4. Context Preparation Logic

#### ‚úÖ ƒêi·ªÉm m·∫°nh hi·ªán t·∫°i

1. **Comprehensive context**:
   - Motif, entities, events, summaries, conflicts
   - Previous chapter ending

2. **Super summary**:
   - Condensed overall story summary
   - Updated after each chapter

#### ‚ùå V·∫•n ƒë·ªÅ cho truy·ªán 300 ch∆∞∆°ng

**V·∫•n ƒë·ªÅ 1: Context Size Explosion**

```python
# Trong main.py._prepare_chapter_context()
context = {
    'related_entities': related_entities,  # T·∫•t c·∫£ entities li√™n quan
    'related_events': related_events,      # T·∫•t c·∫£ events li√™n quan
    ...
}
```

**T√≠nh to√°n:**
- Chapter 1-10: ~20 entities, ~10 events = ~3K tokens
- Chapter 100: ~100 entities, ~50 events = ~15K tokens
- Chapter 250: ~200+ entities, ~100+ events = **~30K+ tokens**

**T√°c ƒë·ªông:**
- V∆∞·ª£t context window c·ªßa nhi·ªÅu models
- Chi ph√≠ API tƒÉng exponentially
- Response quality gi·∫£m do context overload

**V·∫•n ƒë·ªÅ 2: No Arc/Phase Awareness**

```python
# Kh√¥ng c√≥ concept c·ªßa story arc ho·∫∑c phase
# Context chu·∫©n b·ªã gi·ªëng nhau cho t·∫•t c·∫£ chapters
```

**T√°c ƒë·ªông:**
- Kh√¥ng th·ªÉ focus v√†o current arc
- Information t·ª´ arc kh√°c l√†m nhi·ªÖu

**V·∫•n ƒë·ªÅ 3: Super Summary Inflation**

```python
# Super summary ƒë∆∞·ª£c update li√™n t·ª•c
# C√≥ th·ªÉ tr·ªü n√™n qu√° d√†i ·ªü chapter 250
```

**T√°c ƒë·ªông:**
- Super summary kh√¥ng c√≤n "super" condensed
- M·∫•t focus v√†o main plot

---

## üí° ƒê·ªÅ xu·∫•t t·ªëi ∆∞u h√≥a

### T·ªëi ∆∞u 1: Relevance Scoring System

**M·ª•c ti√™u:** ƒê√°nh gi√° m·ª©c ƒë·ªô relevant c·ªßa entity/event v·ªõi chapter hi·ªán t·∫°i

#### 1.1. Entity Relevance Score

```python
def calculate_entity_relevance(entity, current_chapter, outline):
    """
    T√≠nh relevance score 0-1 cho entity.
    
    Factors:
    - Recency: Entity xu·∫•t hi·ªán g·∫ßn ƒë√¢y h∆°n = score cao h∆°n
    - Frequency: Xu·∫•t hi·ªán nhi·ªÅu l·∫ßn = quan tr·ªçng h∆°n
    - Outline match: Entity trong outline = score cao
    - Importance: Entity importance (n·∫øu c√≥)
    """
    score = 0.0
    
    # Factor 1: Recency (40%)
    appear_chapters = entity.get('appear_in_chapters', [])
    if appear_chapters:
        last_appearance = max(appear_chapters)
        chapter_distance = current_chapter - last_appearance
        
        # Decay function: g·∫ßn h∆°n = score cao h∆°n
        if chapter_distance == 0:
            recency_score = 1.0
        elif chapter_distance <= 5:
            recency_score = 0.8
        elif chapter_distance <= 10:
            recency_score = 0.6
        elif chapter_distance <= 30:
            recency_score = 0.4
        elif chapter_distance <= 100:
            recency_score = 0.2
        else:
            recency_score = 0.1
        
        score += recency_score * 0.4
    
    # Factor 2: Frequency (20%)
    frequency = len(appear_chapters)
    max_frequency = min(current_chapter, 50)  # Cap at 50
    frequency_score = min(frequency / max_frequency, 1.0)
    score += frequency_score * 0.2
    
    # Factor 3: Outline match (30%)
    entity_name = entity.get('name', '')
    outline_entities = outline.get('entities', [])
    outline_names = [e.get('name', '') for e in outline_entities]
    
    if entity_name in outline_names:
        score += 1.0 * 0.3
    
    # Factor 4: Importance (10%) - if available
    importance = entity.get('importance', 0.5)
    score += importance * 0.1
    
    return min(score, 1.0)
```

#### 1.2. Event Relevance Score

```python
def calculate_event_relevance(event, current_chapter, outline):
    """
    T√≠nh relevance score 0-1 cho event.
    
    Factors:
    - Recency: Event g·∫ßn h∆°n = relevant h∆°n
    - Importance: Event importance score
    - Character overlap: Event involve characters trong outline
    - Causal chain: Event d·∫´n ƒë·∫øn events hi·ªán t·∫°i
    """
    score = 0.0
    
    # Factor 1: Recency (40%)
    event_chapter = event.get('chapter', 1)
    chapter_distance = current_chapter - event_chapter
    
    if chapter_distance <= 5:
        recency_score = 1.0
    elif chapter_distance <= 10:
        recency_score = 0.8
    elif chapter_distance <= 30:
        recency_score = 0.6
    elif chapter_distance <= 100:
        recency_score = 0.3
    else:
        recency_score = 0.1
    
    score += recency_score * 0.4
    
    # Factor 2: Importance (30%)
    importance = event.get('importance', 0.5)
    score += importance * 0.3
    
    # Factor 3: Character overlap (30%)
    event_characters = set(event.get('characters_involved', []))
    outline_characters = set([c.get('name') for c in outline.get('characters', [])])
    
    if event_characters and outline_characters:
        overlap = len(event_characters & outline_characters) / len(event_characters)
        score += overlap * 0.3
    
    return min(score, 1.0)
```

#### 1.3. Implementation trong ChapterWriter

```python
# Update _prepare_chapter_context() trong main.py

def _prepare_chapter_context(self, chapter_num: int, chapter_outline: Dict[str, Any],
                             motif: Dict[str, Any]) -> Dict[str, Any]:
    """Prepare context v·ªõi relevance scoring."""
    
    # Get ALL entities first
    all_entities = []
    for category, entities in self.entity_manager.entities.items():
        for entity in entities:
            all_entities.append({**entity, 'category': category})
    
    # Score and sort entities
    scored_entities = []
    for entity in all_entities:
        relevance = calculate_entity_relevance(entity, chapter_num, chapter_outline)
        if relevance > 0.1:  # Threshold
            scored_entities.append({
                'entity': entity,
                'relevance': relevance
            })
    
    scored_entities.sort(key=lambda x: x['relevance'], reverse=True)
    
    # Adaptive limit based on chapter number
    base_limit = 20
    if chapter_num > 200:
        entity_limit = 30
    elif chapter_num > 100:
        entity_limit = 25
    else:
        entity_limit = base_limit
    
    related_entities = [item['entity'] for item in scored_entities[:entity_limit]]
    
    # Same for events
    all_events = self.post_processor.events
    scored_events = []
    for event in all_events:
        relevance = calculate_event_relevance(event, chapter_num, chapter_outline)
        if relevance > 0.1:
            scored_events.append({
                'event': event,
                'relevance': relevance
            })
    
    scored_events.sort(key=lambda x: x['relevance'], reverse=True)
    
    # Adaptive limit
    if chapter_num > 200:
        event_limit = 20
    elif chapter_num > 100:
        event_limit = 15
    else:
        event_limit = 10
    
    related_events = [item['event'] for item in scored_events[:event_limit]]
    
    # ... rest of context preparation
    return context
```

---

### T·ªëi ∆∞u 2: Sliding Window Approach

**M·ª•c ti√™u:** Focus v√†o chapters g·∫ßn ƒë√¢y, gi·∫£m context pollution

#### 2.1. Chapter Window Definition

```python
# Trong config.yaml
story:
  context_windows:
    immediate: 5      # Last 5 chapters - highest priority
    recent: 20        # Last 20 chapters - medium priority
    medium: 50        # Last 50 chapters - low priority
    historical: 100   # Last 100 chapters - very low priority
```

#### 2.2. Windowed Entity Selection

```python
def get_entities_with_window(current_chapter, all_entities, window_config):
    """
    L·∫•y entities theo sliding window.
    
    Priority:
    1. Entities trong immediate window (5 chapters) - 100% included
    2. Entities trong recent window (20 chapters) - 80% included
    3. Entities trong medium window (50 chapters) - 50% included
    4. Entities trong historical window (100 chapters) - 20% included
    5. Entities ngo√†i window - 5% only if very important
    """
    categorized = {
        'immediate': [],
        'recent': [],
        'medium': [],
        'historical': [],
        'old': []
    }
    
    for entity in all_entities:
        appear_chapters = entity.get('appear_in_chapters', [])
        if not appear_chapters:
            continue
        
        last_appearance = max(appear_chapters)
        distance = current_chapter - last_appearance
        
        if distance <= window_config['immediate']:
            categorized['immediate'].append(entity)
        elif distance <= window_config['recent']:
            categorized['recent'].append(entity)
        elif distance <= window_config['medium']:
            categorized['medium'].append(entity)
        elif distance <= window_config['historical']:
            categorized['historical'].append(entity)
        else:
            categorized['old'].append(entity)
    
    # Sample from each category v·ªõi priority kh√°c nhau
    selected = []
    
    # Immediate: take all
    selected.extend(categorized['immediate'])
    
    # Recent: take 80%
    recent_limit = int(len(categorized['recent']) * 0.8)
    selected.extend(sorted(categorized['recent'], 
                          key=lambda e: calculate_entity_relevance(e, current_chapter),
                          reverse=True)[:recent_limit])
    
    # Medium: take 50%
    medium_limit = int(len(categorized['medium']) * 0.5)
    selected.extend(sorted(categorized['medium'],
                          key=lambda e: calculate_entity_relevance(e, current_chapter),
                          reverse=True)[:medium_limit])
    
    # Historical: take 20%
    historical_limit = int(len(categorized['historical']) * 0.2)
    selected.extend(sorted(categorized['historical'],
                          key=lambda e: calculate_entity_relevance(e, current_chapter),
                          reverse=True)[:historical_limit])
    
    # Old: only if importance > 0.8
    very_important_old = [e for e in categorized['old'] 
                          if e.get('importance', 0) > 0.8]
    selected.extend(very_important_old[:5])
    
    return selected
```

---

### T·ªëi ∆∞u 3: Enhanced Conflict Management

**M·ª•c ti√™u:** Better prioritization v√† pruning cho 300 chapters

#### 3.1. Conflict Priority Scoring

```python
def calculate_conflict_priority(conflict, current_chapter):
    """
    T√≠nh priority score cho conflict.
    
    Factors:
    - Timeline urgency
    - Staleness (bao l√¢u kh√¥ng ti·∫øn tri·ªÉn)
    - Character involvement
    """
    score = 0.0
    
    # Factor 1: Timeline urgency (40%)
    timeline = conflict.get('timeline', 'medium_term')
    introduced = conflict.get('introduced_chapter', 1)
    chapters_elapsed = current_chapter - introduced
    
    timeline_scores = {
        'immediate': (1.0, 1),   # (base_score, expected_duration)
        'batch': (0.9, 5),
        'short_term': (0.7, 10),
        'medium_term': (0.5, 30),
        'long_term': (0.3, 100),
        'epic': (0.2, 300)
    }
    
    base_score, expected_duration = timeline_scores.get(timeline, (0.5, 30))
    
    # Increase urgency if approaching expected resolution
    if chapters_elapsed >= expected_duration * 0.8:
        urgency = 1.0
    elif chapters_elapsed >= expected_duration * 0.5:
        urgency = 0.8
    else:
        urgency = base_score
    
    score += urgency * 0.4
    
    # Factor 2: Staleness penalty (30%)
    last_mentioned = conflict.get('last_mentioned_chapter', introduced)
    stale_duration = current_chapter - last_mentioned
    
    if stale_duration <= 5:
        freshness = 1.0
    elif stale_duration <= 20:
        freshness = 0.7
    elif stale_duration <= 50:
        freshness = 0.4
    else:
        freshness = 0.1  # Very stale
    
    score += freshness * 0.3
    
    # Factor 3: Character importance (30%)
    characters_involved = conflict.get('characters_involved', [])
    # Assume we have character importance scores
    avg_char_importance = 0.5  # Simplified
    score += avg_char_importance * 0.3
    
    return min(score, 1.0)
```

#### 3.2. Conflict Pruning

```python
def prune_stale_conflicts(conflicts, current_chapter, threshold=100):
    """
    T·ª± ƒë·ªông prune conflicts qu√° c≈© kh√¥ng ƒë∆∞·ª£c nh·∫Øc ƒë·∫øn.
    
    Rules:
    - immediate/batch conflicts: prune n·∫øu > 10 chapters kh√¥ng nh·∫Øc
    - short_term: prune n·∫øu > 30 chapters
    - medium_term: prune n·∫øu > 100 chapters
    - long_term/epic: kh√¥ng prune
    """
    pruning_rules = {
        'immediate': 10,
        'batch': 10,
        'short_term': 30,
        'medium_term': 100,
        'long_term': None,  # Never prune
        'epic': None
    }
    
    active_conflicts = []
    pruned_conflicts = []
    
    for conflict in conflicts:
        if conflict.get('status') != 'active':
            continue
        
        timeline = conflict.get('timeline', 'medium_term')
        prune_threshold = pruning_rules.get(timeline)
        
        if prune_threshold is None:
            # Don't prune long_term/epic
            active_conflicts.append(conflict)
            continue
        
        introduced = conflict.get('introduced_chapter', 1)
        last_mentioned = conflict.get('last_mentioned_chapter', introduced)
        stale_duration = current_chapter - last_mentioned
        
        if stale_duration > prune_threshold:
            # Auto-resolve as "abandoned"
            conflict['status'] = 'abandoned'
            conflict['resolution_chapter'] = current_chapter
            conflict['resolution_note'] = f'Auto-pruned due to {stale_duration} chapters of inactivity'
            pruned_conflicts.append(conflict)
        else:
            active_conflicts.append(conflict)
    
    return active_conflicts, pruned_conflicts
```

#### 3.3. Conflict Selection for Batch

```python
def select_conflicts_for_batch(all_conflicts, current_batch, current_chapter):
    """
    Select conflicts for next batch with priority scoring.
    """
    # First prune stale conflicts
    active_conflicts, pruned = prune_stale_conflicts(all_conflicts, current_chapter)
    
    # Score remaining conflicts
    scored_conflicts = []
    for conflict in active_conflicts:
        priority = calculate_conflict_priority(conflict, current_chapter)
        scored_conflicts.append({
            'conflict': conflict,
            'priority': priority
        })
    
    # Sort by priority
    scored_conflicts.sort(key=lambda x: x['priority'], reverse=True)
    
    # Select top N based on batch
    # Early batches: fewer conflicts
    # Later batches: more conflicts
    if current_batch <= 5:
        limit = 5
    elif current_batch <= 20:
        limit = 8
    elif current_batch <= 40:
        limit = 12
    else:
        limit = 15
    
    selected = [item['conflict'] for item in scored_conflicts[:limit]]
    
    return selected, pruned
```

---

### T·ªëi ∆∞u 4: Arc-based Context Management

**M·ª•c ti√™u:** Organize story theo arcs, focus context theo arc hi·ªán t·∫°i

#### 4.1. Story Arc Definition

```python
# Trong config ho·∫∑c checkpoint metadata
story_arcs = [
    {
        "arc_id": "arc_1",
        "name": "Kh·ªüi ƒë·∫ßu tu luy·ªán",
        "start_chapter": 1,
        "end_chapter": 50,
        "main_conflicts": ["conflict_001", "conflict_002"],
        "main_characters": ["L√Ω H·∫°o", "Tr·∫ßn L·ª±c"],
        "themes": ["self-discovery", "power-growth"]
    },
    {
        "arc_id": "arc_2",
        "name": "T√¥ng m√¥n tranh ƒë·∫•u",
        "start_chapter": 51,
        "end_chapter": 120,
        "main_conflicts": ["conflict_010", "conflict_015"],
        "main_characters": ["L√Ω H·∫°o", "L√¢m Thanh V√¢n", "Tr∆∞∆°ng ƒê·∫°o"],
        "themes": ["faction-war", "loyalty"]
    },
    # ... more arcs
]
```

#### 4.2. Arc-aware Context Preparation

```python
def get_current_arc(chapter_num, story_arcs):
    """X√°c ƒë·ªãnh arc hi·ªán t·∫°i."""
    for arc in story_arcs:
        if arc['start_chapter'] <= chapter_num <= arc['end_chapter']:
            return arc
    return None

def prepare_arc_aware_context(chapter_num, chapter_outline, all_entities, all_events, all_conflicts):
    """
    Chu·∫©n b·ªã context v·ªõi arc awareness.
    
    Priority:
    1. Entities/events/conflicts trong current arc - 70%
    2. Entities/events/conflicts t·ª´ previous arc - 20%
    3. Global important entities/events - 10%
    """
    current_arc = get_current_arc(chapter_num, story_arcs)
    
    if not current_arc:
        # Fallback to standard context
        return prepare_standard_context(...)
    
    # Get current arc entities
    arc_main_chars = set(current_arc.get('main_characters', []))
    arc_conflicts = set(current_arc.get('main_conflicts', []))
    
    # Filter entities
    arc_entities = []
    other_entities = []
    
    for entity in all_entities:
        if entity.get('name') in arc_main_chars:
            arc_entities.append(entity)
        else:
            other_entities.append(entity)
    
    # Allocate 70% to arc entities, 30% to others
    arc_limit = int(entity_total_limit * 0.7)
    other_limit = entity_total_limit - arc_limit
    
    selected_entities = arc_entities[:arc_limit]
    selected_entities.extend(sorted(other_entities, 
                                   key=lambda e: calculate_entity_relevance(e, chapter_num),
                                   reverse=True)[:other_limit])
    
    # Same for events and conflicts
    # ...
    
    return {
        'arc_info': current_arc,
        'entities': selected_entities,
        'events': selected_events,
        'conflicts': selected_conflicts,
        # ...
    }
```

---

### T·ªëi ∆∞u 5: Adaptive Limits Based on Story Phase

**M·ª•c ti√™u:** ƒêi·ªÅu ch·ªânh limits theo phase c·ªßa story

#### 5.1. Phase Definition

```python
def get_story_phase(chapter_num, total_planned_chapters=300):
    """
    X√°c ƒë·ªãnh phase c·ªßa story.
    
    Phases:
    - Introduction (0-10%): Gi·ªõi thi·ªáu th·∫ø gi·ªõi, nh√¢n v·∫≠t
    - Rising Action (10-30%): X√¢y d·ª±ng conflicts
    - Development (30-70%): Main story arcs
    - Climax (70-90%): Cao tr√†o
    - Resolution (90-100%): K·∫øt th√∫c
    """
    progress = chapter_num / total_planned_chapters
    
    if progress <= 0.1:
        return 'introduction'
    elif progress <= 0.3:
        return 'rising_action'
    elif progress <= 0.7:
        return 'development'
    elif progress <= 0.9:
        return 'climax'
    else:
        return 'resolution'
```

#### 5.2. Phase-based Limits

```python
def get_phase_limits(phase):
    """
    Tr·∫£ v·ªÅ limits cho t·ª´ng phase.
    
    Introduction: √çt entities/events (focus on world-building)
    Development: Nhi·ªÅu entities/events (complex story)
    Resolution: Gi·∫£m d·∫ßn (focus on main threads)
    """
    limits = {
        'introduction': {
            'entities': 15,
            'events': 8,
            'conflicts': 5,
            'context_window': 5
        },
        'rising_action': {
            'entities': 25,
            'events': 15,
            'conflicts': 8,
            'context_window': 10
        },
        'development': {
            'entities': 35,
            'events': 20,
            'conflicts': 12,
            'context_window': 20
        },
        'climax': {
            'entities': 30,  # Focus l·∫°i
            'events': 25,    # Nhi·ªÅu events ƒë·ªÉ buildup
            'conflicts': 15,
            'context_window': 30
        },
        'resolution': {
            'entities': 20,  # Focus on main characters
            'events': 15,
            'conflicts': 8,  # Resolve conflicts
            'context_window': 50  # Need full story context
        }
    }
    
    return limits.get(phase, limits['development'])
```

---

### T·ªëi ∆∞u 6: Entity & Event Importance Tracking

**M·ª•c ti√™u:** Track importance c·ªßa entities/events t·ª± ƒë·ªông

#### 6.1. Entity Importance Auto-calculation

```python
def calculate_entity_importance(entity, all_events, all_conflicts):
    """
    T·ª± ƒë·ªông t√≠nh importance c·ªßa entity.
    
    Factors:
    - Frequency of appearance
    - Involvement in important events
    - Involvement in conflicts
    - Role (main character > supporting > minor)
    """
    importance = 0.0
    
    # Factor 1: Appearance frequency (30%)
    appearances = len(entity.get('appear_in_chapters', []))
    # Normalize by total chapters seen
    frequency_score = min(appearances / 50, 1.0)
    importance += frequency_score * 0.3
    
    # Factor 2: Event involvement (40%)
    entity_name = entity.get('name', '')
    involved_events = [e for e in all_events 
                       if entity_name in e.get('characters_involved', []) or 
                          entity_name in e.get('entities_involved', [])]
    
    if involved_events:
        # Weighted by event importance
        avg_event_importance = sum(e.get('importance', 0.5) for e in involved_events) / len(involved_events)
        event_count_score = min(len(involved_events) / 20, 1.0)
        event_score = (avg_event_importance + event_count_score) / 2
        importance += event_score * 0.4
    
    # Factor 3: Conflict involvement (30%)
    involved_conflicts = [c for c in all_conflicts
                         if entity_name in c.get('characters_involved', [])]
    
    if involved_conflicts:
        active_conflicts = [c for c in involved_conflicts if c.get('status') == 'active']
        conflict_score = len(active_conflicts) / max(len(involved_conflicts), 1)
        importance += conflict_score * 0.3
    
    return min(importance, 1.0)

def update_all_entity_importance(entity_manager, post_processor):
    """Update importance scores for all entities."""
    all_events = post_processor.events
    all_conflicts = post_processor.conflicts
    
    for category, entities in entity_manager.entities.items():
        for entity in entities:
            importance = calculate_entity_importance(entity, all_events, all_conflicts)
            entity['importance'] = importance
            
            # Also update last_mentioned_chapter
            appear_chapters = entity.get('appear_in_chapters', [])
            if appear_chapters:
                entity['last_mentioned_chapter'] = max(appear_chapters)
    
    entity_manager._save_entities()
```

#### 6.2. Periodic Importance Update

```python
# Trong main.py, sau m·ªói batch
def finalize_batch(self, batch_num):
    """Finalize batch v√† update importance scores."""
    # Update entity importance
    self._update_entity_importance()
    
    # Update event relevance (decay old events)
    self._update_event_relevance()
    
    # Prune stale conflicts
    self._prune_stale_conflicts()
    
def _update_entity_importance(self):
    """Update importance scores every batch."""
    update_all_entity_importance(self.entity_manager, self.post_processor)
    self.logger.info("Updated entity importance scores")
```

---

## üìä T√°c ƒë·ªông d·ª± ki·∫øn

### 1. Token Usage Reduction

**Hi·ªán t·∫°i (Chapter 250):**
- Entities: ~200 entities √ó ~150 tokens = ~30,000 tokens
- Events: ~100 events √ó ~100 tokens = ~10,000 tokens
- **Total context:** ~40,000 tokens

**Sau t·ªëi ∆∞u (Chapter 250):**
- Entities: ~30 entities (scored + windowed) √ó ~150 tokens = ~4,500 tokens
- Events: ~20 events (scored + windowed) √ó ~100 tokens = ~2,000 tokens
- **Total context:** ~6,500 tokens

**Ti·∫øt ki·ªám:** ~84% token usage

### 2. Quality Improvement

- ‚úÖ More relevant context ‚Üí Better narrative coherence
- ‚úÖ Recency focus ‚Üí Better continuation from previous chapters
- ‚úÖ Conflict management ‚Üí Better long-term plot development
- ‚úÖ Arc awareness ‚Üí Better story structure

### 3. Scalability

- ‚úÖ Can scale to 500+ chapters with same approach
- ‚úÖ Context size stays bounded
- ‚úÖ Adaptive limits prevent overload

---

## üöÄ Implementation Roadmap

### Phase 1: Core Scoring (Priority: High)
- [ ] Implement `calculate_entity_relevance()`
- [ ] Implement `calculate_event_relevance()`
- [ ] Implement `calculate_conflict_priority()`
- [ ] Update `_prepare_chapter_context()` to use scoring

### Phase 2: Windowing (Priority: High)
- [ ] Add window config to `config.yaml`
- [ ] Implement `get_entities_with_window()`
- [ ] Implement `get_events_with_window()`
- [ ] Test with existing stories

### Phase 3: Conflict Management (Priority: Medium)
- [ ] Implement `prune_stale_conflicts()`
- [ ] Update conflict selection logic
- [ ] Add `last_mentioned_chapter` tracking

### Phase 4: Importance Tracking (Priority: Medium)
- [ ] Implement `calculate_entity_importance()`
- [ ] Add periodic importance updates
- [ ] Add importance field to entity schema

### Phase 5: Arc Management (Priority: Low)
- [ ] Design arc data structure
- [ ] Implement arc detection/creation
- [ ] Add arc-aware context preparation

### Phase 6: Testing & Validation (Priority: High)
- [ ] Generate test story with 50 chapters
- [ ] Measure token usage improvement
- [ ] Validate narrative quality
- [ ] Adjust scoring weights

---

## üìù K·∫øt lu·∫≠n

### Logic hi·ªán t·∫°i (v1.3.1)

**ƒê√°nh gi√°:** ‚ö†Ô∏è **Kh√¥ng ƒë·ªß ch·∫∑t ch·∫Ω cho truy·ªán 300 ch∆∞∆°ng**

**L√Ω do:**
1. ‚ùå Kh√¥ng c√≥ recency/relevance scoring
2. ‚ùå Fixed limits kh√¥ng adaptive
3. ‚ùå Context size kh√¥ng bounded
4. ‚ùå Conflicts kh√¥ng ƒë∆∞·ª£c pruned
5. ‚úÖ C√≥ chapter-based filtering (good start)
6. ‚úÖ C√≥ timeline-based conflict tracking (good foundation)

### Sau t·ªëi ∆∞u h√≥a

**ƒê√°nh gi√°:** ‚úÖ **ƒê·ªß ch·∫∑t ch·∫Ω v√† scalable cho 300+ ch∆∞∆°ng**

**C·∫£i ti·∫øn:**
1. ‚úÖ Relevance scoring system
2. ‚úÖ Sliding window approach
3. ‚úÖ Adaptive limits theo phase
4. ‚úÖ Automatic conflict pruning
5. ‚úÖ Importance tracking
6. ‚úÖ Arc-based organization (optional)

---

**Khuy·∫øn ngh·ªã:** Implement **Phase 1-3** tr∆∞·ªõc ƒë·ªÉ c√≥ impact l·ªõn nh·∫•t v·ªõi effort h·ª£p l√Ω.

**Timeline ∆∞·ªõc t√≠nh:** 
- Phase 1-2: 2-3 ng√†y
- Phase 3: 1-2 ng√†y
- Testing: 1-2 ng√†y
- **Total:** ~1 tu·∫ßn

---

**T√†i li·ªáu n√†y:** `LONG_FORM_STORY_ANALYSIS.md`  
**Ng√†y t·∫°o:** 2025-11-07  
**Version:** 1.0
